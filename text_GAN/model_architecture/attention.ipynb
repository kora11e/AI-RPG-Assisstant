{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 2.6.0+cpu\n",
      "CUDA available: False\n",
      "CUDA is not available. Ensure you have a GPU for optimal performance.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check for CUDA and PyTorch version compatibility\n",
    "print(f\"Using PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Optional: check the device name if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Ensure you have a GPU for optimal performance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3462b7e9afb47f28d9de693da9a2c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 16:38:38 INFO: Downloaded file to C:\\Users\\X\\stanza_resources\\resources.json\n",
      "2025-04-17 16:38:38 INFO: Downloading default packages for language: pl (Polish) ...\n",
      "2025-04-17 16:38:38 INFO: File exists: C:\\Users\\X\\stanza_resources\\pl\\default.zip\n",
      "2025-04-17 16:38:41 INFO: Finished downloading models and saved to C:\\Users\\X\\stanza_resources\n",
      "2025-04-17 16:38:41 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed9712a4958145829120ce4381aac45e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 16:38:41 INFO: Downloaded file to C:\\Users\\X\\stanza_resources\\resources.json\n",
      "2025-04-17 16:38:41 WARNING: Language pl package default expects mwt, which has been added\n",
      "2025-04-17 16:38:41 INFO: Loading these models for language: pl (Polish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | pdb     |\n",
      "| mwt       | pdb     |\n",
      "=======================\n",
      "\n",
      "2025-04-17 16:38:41 WARNING: GPU requested, but is not available!\n",
      "2025-04-17 16:38:41 INFO: Using device: cpu\n",
      "2025-04-17 16:38:41 INFO: Loading: tokenize\n",
      "2025-04-17 16:38:41 INFO: Loading: mwt\n",
      "2025-04-17 16:38:41 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'łzy': 124, 'padały': 2, 'na': 636, 'cremoński': 4, 'lakier': 5, 'szkoda': 6, 'nie': 544, 'wolno': 8, 'było': 423, 'niszczyć': 10, 'przedmiotu': 11, 'który': 199, 'ojciec': 14, 'biedaczysko': 15, 'wydał': 16, 'całą': 17, 'schedę': 18, 'po': 669, 'luizie': 20, 'otarła': 21, 'je': 22, 'lewą': 23, 'umęczoną': 24, 'ręką': 25, 'wszedł': 26, 'adam': 27, 'zawiało': 28, 'wodą': 29, 'kwiatową': 30, 'maréchal': 31, 'niel': 32, 'starannie': 33, 'domykał': 34, 'drzwi': 35, 'za': 36, 'sobą': 37, 'trwała': 38, 'dalej': 634, 'w': 672, 'bezruchu': 41, 'pan': 143, 'dyrektor': 43, 'był': 388, 'nieobecny': 45, 'a': 578, 'róża': 621, 'stała': 48, 'ppiecem': 49, 'czekając': 50, 'kiedy': 51, 'panna': 52, 'aniela': 53, 'bądska': 54, 'ukończy': 55, 'gamy': 56, 'i': 659, 'zechce': 58, 'łaskawie': 59, 'zaakompaniować': 60, 'jedynej': 67, 'uczennicy': 68, 'papy': 63, 'moment': 64, 'musical': 65, 'szuberta': 66, 'pierwszej': 69, 'adeptce': 70, 'skrzypiec': 638, 'warszawskiego': 72, 'konserwatorium': 73, 'tamce': 75, 'czarnej': 76, 'chudej': 77, 'dziewczynie': 78, 'z': 663, 'rumieńcami': 80, 'latającymi': 81, 'jak': 642, 'płomień': 83, 'śniadych': 85, 'policzkach': 86, 'lśniącym': 88, 'długim': 89, 'warkoczem': 90, 'kacapską': 92, 'wymową': 93, 'niemodnym': 96, 'medalionem': 97, 'szyi': 99, 'to': 613, 'wszystko': 101, 'nowe': 104, 'także': 666, 'były': 106, 'miesięczne': 107, 'wędrówki': 108, 'grób': 110, 'męża': 111, 'sjesty': 113, 'cmentarnej': 115, 'ławeczce': 116, 'ze': 550, 'wzrokiem': 118, 'żarliwie': 119, 'utkwionym': 120, 'darninę': 122, 'nocach': 126, 'nasłuchiwanie': 128, 'czy': 129, 'stenia': 130, 'kaszle': 132, 'rumieńce': 134, 'wstydu': 135, 'gdy': 136, 'pytano': 137, 'przy': 155, 'wnukach': 139, 'gdzież': 141, 'zięć': 144, 'cóż': 146, 'o': 529, 'panu': 149, 'inżynierze': 150, 'słychać': 152, 'prawie': 153, 'wesoła dokończyła': 154, 'pomocy': 156, 'krokodyla': 157, 'zdejmowania': 158, 'chusty': 159, 'strzepnęła': 160, 'ją': 348, 'złożyła': 162, 'odniosła': 163, 'tamże': 164, 'gdzie': 165, 'portrecik': 166, 'ojca': 167, 'telefon': 289, 'zadzwonił': 169, 'upudrowała': 170, 'się': 655, 'gorączkowo': 172, 'przybrała': 173, 'oschły': 174, 'wyraz': 175, 'twarzy': 176, 'może': 177, 'marta': 615, 'podeszła': 180, 'do': 591, 'aparatu': 182, 'ledwie': 183, 'zdjęła': 184, 'słuchawkę': 185, 'sabina': 186, 'przycwałowała': 187, 'słoniowym': 188, 'truchtem': 189, 'przez': 250, 'korytarz': 191, 'milczała': 193, 'słuchała': 194, 'napomnień': 195, 'ptasiego': 197, 'szczebiotu': 198, 'niczego': 542, 'obowiązuje': 203, 'gdyż': 204, 'nic': 205, 'ludzkiego': 206, 'oznacza': 208, 'oczy': 209, 'powlekła': 210, 'biaława': 211, 'szklistość': 212, 'co': 213, 'wzmogło': 214, 'tajemnicę': 215, 'spojrzenia': 216, 'wydawała': 217, 'spoczywać': 219, 'niezmiernym': 221, 'wysiłku': 222, 'szczęśliwa': 223, 'zdobyczy': 225, 'pewna': 226, 'własnej': 227, 'potęgi': 228, 'wreszcie': 677, 'syta': 230, 'wiedzy': 231, 'spokoju': 233, 'uśmiechnęła': 234, 'córki': 494, 'swej': 239, 'błogiej': 240, 'dali': 241, 'radio': 242, 'gra': 243, 'close': 244, 'your': 245, 'eyes': 246, 'wzburzona': 248, 'pominięciem': 249, 'córkę': 251, 'swojej': 551, 'wizyty': 253, 'zirytowana': 254, 'brakiem': 255, 'szacunku': 256, 'tutaj': 257, 'tym': 259, 'zięciowskim': 260, 'domu': 261, 'dla': 429, 'empirowego': 263, 'stolika': 264, 'zmęczona': 265, 'gniewem': 266, 'usłyszała': 267, 'pieśń': 268, 'pragnęła': 270, 'zapomnieć': 271, 'jaki': 272, 'jest': 618, 'dzień': 436, 'jaka': 275, 'sytuacja': 276, 'zerknęła': 277, 'lustro': 279, 'obciągnęła': 280, 'sobie': 585, 'sweter': 283, 'czerwone': 285, 'skrzydła': 286, 'rzuciła': 627, 'stając': 290, 'progu': 292, 'stanę': 293, 'ła': 294, 'twarzą': 295, 'twarz': 297, 'matką': 299, 'wysoko': 301, 'osadzona': 302, 'patrzyła': 303, 'przed': 304, 'siebie': 561, 'nad': 306, 'miarę': 307, 'otwartymi': 308, 'oczami': 309, 'tych': 311, 'oczach': 312, 'odbijał': 313, 'widok': 315, 'nietutejszy': 316, 'źrenice': 317, 'usiłowały': 318, 'go': 319, 'ogarnąć': 320, 'całej': 322, 'jego': 323, 'dzikiej': 324, 'wielkości': 325, 'rozszerzały': 326, 'rosły': 328, 'ciągle': 329, 'smudze': 332, 'nieziemskiego': 333, 'widzenia': 334, 'szła': 335, 'ścierpnięta': 336, 'uklękła': 337, 'opasała': 338, 'ramionami': 339, 'duże': 340, 'ciepłe': 341, 'ciało': 342, 'przytuliła': 343, 'głowę': 344, 'łona': 346, 'które': 425, 'wydało': 349, 'światu': 350, 'okresie': 352, 'szkolnym': 353, 'inaczej': 355, 'przedstawiała': 356, 'sprawa': 358, 'koleżanek': 359, 'raz': 360, 'roku': 362, 'tylko': 635, 'bywały': 364, 'zapraszane': 365, 'wtedy': 367, 'występowała': 368, 'wspaniałym': 370, 'przyjęciem': 371, 'stół': 372, 'uginał': 373, 'ptortami': 375, 'owocami': 376, 'kremami': 377, 'mebli': 379, 'zdejmowano': 380, 'pokrowce': 381, 'srebra': 382, 'błyszczały': 383, 'posadzki': 384, 'lśniły': 385, 'program': 386, 'zabawy': 387, 'ściśle': 389, 'ustalony': 390, 'zazwyczaj': 391, 'latarnia': 392, 'czarnoksięska': 393, 'zajmowała': 394, 'gros': 395, 'czasu': 396, 'później': 397, 'należało': 398, 'kolejno': 399, 'deklamować': 400, 'wiersze': 401, 'godzinę': 407, 'trwał': 403, 'talar': 404, 'pierścionek': 406, 'tańce': 408, 'przeplatane': 409, 'grą': 410, 'szarady': 412, 'lemoniadę': 414, 'ósmej': 416, 'wieczór': 417, 'gości': 418, 'żegnano': 419, 'ewa': 420, 'éveline': 421, 'imię': 424, 'nadała': 426, 'jej': 427, 'luiza': 428, 'względów': 430, 'prestiżowych': 431, 'pamiętała': 433, 'dobrze': 434, 'ten': 586, 'jesienią': 437, 'niedzielę': 439, 'szły': 440, 'ciotką': 442, 'obrzędowy': 444, 'spacer': 445, 'łazienek': 447, 'placem': 448, 'wareckim': 449, 'ulicą': 450, 'szpitalną': 451, 'bracką': 452, 'alejami': 453, 'dorożki': 454, 'kabriolety': 456, 'turkotały': 457, 'wyboistym': 459, 'bruku': 460, 'pojazdach': 462, 'piętrzyły': 463, 'damy': 465, 'dziewczynki': 467, 'szumiące': 468, 'krochmalu': 469, 'jedwabiu': 470, 'liberty': 471, 'ostrowłosej': 472, 'sztywnej': 473, 'wełny': 474, 'panowie': 475, 'cylindrach': 477, 'melonikach': 480, 'tkwili': 481, 'bokiem': 482, 'przednich': 484, 'ławeczkach': 485, 'wówczas': 486, 'martę': 487, 'strach': 488, 'przejął': 489, 'więc': 616, 'śpiew': 493, 'przestał': 495, 'być': 496, 'własną': 497, 'sprawą': 498, 'róży': 595, 'pojawiły': 501, 'jakieś': 503, 'inne': 504, 'sprawy': 505, 'prawda': 506, 'codzienny': 507, 'nieubłagany': 508, 'przymus': 509, 'stąd': 512, 'dotąd': 513, 'masz': 514, 'nauczyć': 516, 'pamiętaj': 517, 'żeby': 518, 'następnym': 519, 'razem': 520, 'powtórzył': 522, 'błąd': 525, 'gdyby': 527, 'chodziło': 528, 'małą': 530, 'bezwolną': 531, 'dziewczynę': 532, 'dokuczało': 534, 'marcie': 535, 'żywego': 537, 'ale': 538, 'mimo': 539, 'wszystkie': 540, 'bunty': 541, 'tak': 543, 'lubiła': 545, 'widzieć': 547, 'matkę': 548, 'szczęśliwą': 549, 'przyczyny': 552, 'ciskała': 554, 'nuty': 555, 'zamykała': 556, 'trzaskiem': 559, 'u': 560, 'ciągu': 563, 'następnych': 564, 'lekcyj': 565, 'rozbujanie': 566, 'frazy': 567, 'dawało': 568, 'powściągnąć': 570, 'styl': 572, 'barwę': 574, 'uczuciową': 575, 'poddawała': 576, 'jednak': 579, 'ostateczny': 580, 'rezultat': 581, 'pracy': 582, 'zawierał': 583, 'urzekający': 587, 'pierwiastek': 588, 'nowość': 589, 'którą': 590, 'trudu': 592, 'kompozytora': 593, 'dodawała': 596, 'zasobów': 599, 'własnego': 600, 'organizmu': 601, 'chwytała': 603, 'dziewczęce': 604, 'fluidy': 605, 'przesączone': 606, 'melodie': 608, 'doznając': 609, 'głębokiego': 610, 'wzruszenia': 611, 'taka': 617, 'córeczka': 619, 'adama': 620, 'opuściła': 622, 'ręce': 623, 'siadła': 624, 'nogi': 625, 'drżały': 626, 'smyczek': 628, 'księżycowa': 629, 'orkiestra': 630, 'pbatutą': 631, 'brahmsa': 632, 'grała': 633, 'miejscu': 637, 'wystąpiła': 639, 'cisza': 652, 'czarna': 641, 'zaskórna': 643, 'woda': 644, 'jeszcze': 645, 'tu': 646, 'ówdzie': 648, 'błyskał': 649, 'refleks': 650, 'sola': 651, 'przecież': 653, 'czyniła': 654, 'coraz': 656, 'głębsza': 657, 'szersza': 658, 'pochłaniała': 660, 'resztkę': 661, 'wibracji': 662, 'wolna': 664, 'milkły': 665, 'widmowe': 667, 'instrumenty': 668, 'jednemu': 670, 'wsiąkały': 671, 'próżnię': 673, 'chaos': 674, 'bezdźwięczny': 675, 'pokrył': 676, 'harmonię': 678}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from transformers import BertTokenizer\n",
    "import stanza\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "text_data = {}\n",
    "text_data_raw = []\n",
    "\n",
    "stanza.download('pl')\n",
    "nlp = stanza.Pipeline('pl', use_gpu=True, processors='tokenize')\n",
    "                                          # for polish language\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "with open('../../data/text_data/other/csv/text_1.txt', 'r', encoding='utf-8') as f:\n",
    "   dat = f.read()\n",
    "   \n",
    "   doc = nlp(dat)\n",
    "   for i, sentence in enumerate(doc.sentences):\n",
    "      for token in sentence.tokens:\n",
    "         text_data[token.text] = token.id[0]\n",
    "\n",
    "print(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'110': 0, 'a': 4, 'abraham': 8, 'aby': 9, 'ale': 13, 'ameryki': 14, 'ani': 15, 'anielki': 16, 'asystent': 17, 'bardzo': 19, 'batorego': 20, 'bał': 21, 'bez': 23, 'bełkocząc': 24, 'blady': 25, 'bliski': 26, 'bo': 28, 'boruch': 29, 'borucha': 31, 'boruchem': 32, 'bowiem': 33, 'brat': 34, 'brodą': 35, 'brudne': 36, 'bruk': 37, 'brzydka': 38, 'bulgotał': 39, 'był': 43, 'była': 46, 'byłam': 47, 'było': 49, 'były': 50, 'ból': 51, 'będzie': 52, 'cały': 53, 'całą': 54, 'charakteru': 55, 'chciał': 56, 'chciałbym': 57, 'chirurg': 62, 'chirurgiem': 63, 'chirurgowi': 65, 'chmury': 66, 'chodnika': 67, 'chodź': 68, 'chorej': 69, 'chorobliwy': 70, 'choć': 71, 'chwili': 72, 'chwilowo': 73, 'chęć': 74, 'chłopcy': 75, 'cichaczem': 76, 'cicho': 77, 'cieniu': 78, 'cierpiał': 79, 'co': 80, 'coś': 82, 'cysty': 83, 'czajnik': 84, 'czapeczce': 85, 'czarna': 86, 'czarną': 87, 'czasie': 88, 'czekał': 89, 'czemu': 90, 'cztery': 91, 'czujesz': 92, 'czy': 93, 'czym': 94, 'czymkolwiek': 95, 'część': 96, 'człowiek': 97, 'daleko': 98, 'dalsze': 100, 'deszcz': 101, 'deszczowe': 102, 'deszczowym': 103, 'do': 113, 'dobroci': 114, 'dobrze': 115, 'doktorze': 116, 'dokąd': 117, 'dolary': 118, 'dolegliwościach': 119, 'domu': 123, 'dopiero': 124, 'dorożce': 125, 'dorożką': 126, 'dorożkę': 127, 'dowiedzieć': 128, 'dowodem': 129, 'drogę': 130, 'drzwi': 133, 'drżący': 134, 'dudniał': 135, 'duszy': 136, 'duże': 137, 'dwudziestego': 138, 'dyrektor': 139, 'dyrektora': 140, 'dzieciaki': 141, 'dziwmy': 142, 'dół': 143, 'elektrotechnika': 144, 'elektryczna': 145, 'epilepsją': 146, 'fakt': 147, 'fartuch': 148, 'febrze': 149, 'firanki': 150, 'firankę': 151, 'fortepianie': 152, 'gankiem': 153, 'ganku': 154, 'gazetę': 155, 'gdy': 159, 'gdyby': 160, 'gdyż': 161, 'giętkie': 162, 'go': 164, 'gold': 169, 'goldowi': 170, 'grają': 171, 'graniczył': 172, 'grozi': 173, 'grzmotem': 174, 'gwałtownie': 175, 'gęsią': 176, 'głosów': 177, 'głowa': 178, 'głowie': 179, 'głowę': 180, 'huczał': 181, 'huźha': 182, 'i': 214, 'idzie': 215, 'innym': 216, 'jak': 227, 'jakaś': 228, 'jakby': 229, 'jaki': 230, 'jakiegoś': 231, 'jakimś': 232, 'jakąś': 233, 'jechaliśmy': 234, 'jeden': 235, 'jedna': 236, 'jednocześnie': 237, 'jedzie': 238, 'jego': 240, 'jej': 241, 'jest': 243, 'jestem': 244, 'już': 245, 'ją': 246, 'kamienicy': 247, 'każdym': 248, 'kimś': 249, 'klakson': 250, 'klucz': 251, 'km': 252, 'kobiece': 253, 'kobieta': 254, 'kogoś': 255, 'kolację': 256, 'kolacyjnej': 257, 'kolanach': 258, 'koniowi': 259, 'korytarzu': 260, 'koło': 261, 'końskiego': 262, 'krawca': 264, 'krawcowi': 265, 'krawiec': 268, 'kroków': 269, 'kropla': 270, 'krzyczeli': 271, 'krzyknął': 272, 'księżyc': 274, 'która': 275, 'które': 277, 'którego': 278, 'który': 279, 'ku': 281, 'kudłatą': 282, 'kurzem': 283, 'kółkach': 284, 'lampa': 285, 'lecz': 290, 'limuzyna': 291, 'ma': 292, 'mam': 293, 'marchewka': 294, 'maskując': 295, 'medyk': 296, 'mi': 299, 'miastem': 300, 'miał': 301, 'mieli': 302, 'milczał': 303, 'miotający': 304, 'miotłą': 305, 'miękkości': 306, 'mknącą': 307, 'mknęła': 308, 'mknęły': 309, 'mniej': 310, 'moją': 311, 'moralnej': 312, 'mu': 317, 'murzyńską': 318, 'muszą': 319, 'myła': 320, 'mówił': 321, 'męką': 322, 'męża': 323, 'na': 349, 'nachalnym': 350, 'nad': 352, 'nadziejny': 353, 'najwyższym': 354, 'namacalne': 355, 'naprzeciw': 356, 'następnej': 357, 'nasycenie': 358, 'nasłuchiwał': 359, 'natychmiast': 362, 'naumyślnie': 363, 'nawet': 366, 'nałożyli': 367, 'nerwicę': 368, 'ni': 370, 'nich': 371, 'niczyich': 372, 'nie': 383, 'niebo': 384, 'niechybną': 385, 'niecierpliwie': 386, 'niego': 388, 'niej': 389, 'niemu': 390, 'nieobecność': 391, 'nieodpartym': 392, 'nieruchomym': 393, 'niespokojnie': 394, 'nieszczęśliwy': 396, 'niezdolność': 397, 'nigdy': 398, 'niklowe': 399, 'nim': 401, 'niosła': 402, 'niska': 403, 'nią': 404, 'niż': 405, 'nocną': 406, 'o': 411, 'obcisłej': 412, 'obecnie': 413, 'obicia': 414, 'obie': 415, 'obok': 416, 'obrał': 417, 'oburzenia': 418, 'obłoku': 419, 'obłęd': 420, 'oczu': 421, 'oczy': 422, 'odbierały': 423, 'oddychać': 424, 'odwrócić': 425, 'ogień': 426, 'ognista': 427, 'ogona': 428, 'ogół': 429, 'ojciec': 430, 'okna': 431, 'on': 432, 'operacji': 434, 'opowiadanie': 435, 'opowiem': 436, 'ostatni': 438, 'osłupieniu': 439, 'otworzył': 440, 'paczkę': 441, 'palce': 442, 'paliła': 443, 'pamięci': 444, 'pamiętam': 445, 'pan': 446, 'pana': 448, 'panowanie': 449, 'panu': 450, 'parę': 451, 'patrzył': 454, 'pblachą': 455, 'pewnie': 456, 'piecu': 457, 'pierwsza': 458, 'pierwsze': 459, 'pierwszym': 460, 'piosenkę': 461, 'po': 463, 'pochylił': 464, 'poczuł': 465, 'podawał': 466, 'podał': 467, 'podobnego': 468, 'podstawy': 469, 'podsłuchując': 470, 'podwórka': 471, 'podłogę': 472, 'pogrzeb': 473, 'pogwizdywał': 474, 'pokoju': 476, 'pokrył': 477, 'pomnika': 478, 'pomyślał': 480, 'poniekąd': 481, 'popatrzyli': 482, 'porze': 483, 'porównywając': 484, 'porównywał': 485, 'postanowiłam': 486, 'postać': 487, 'posuniętą': 488, 'posłuszne': 489, 'potem': 491, 'potwornie': 492, 'powiedziała': 493, 'powrotem': 494, 'pozamykane': 495, 'pozorować': 496, 'pożegnania': 497, 'ppachą': 498, 'pracowni': 499, 'prawdy': 500, 'prawdziwej': 501, 'progu': 502, 'proroczą': 503, 'protestu': 504, 'przebieg': 505, 'przeciwnie': 506, 'przed': 508, 'przedpokoju': 509, 'przejmowania': 510, 'przekonana': 511, 'przekradł': 512, 'przez': 514, 'przeżył': 515, 'przychwycił': 516, 'przypominał': 517, 'przypominało': 518, 'przypuszczalnie': 519, 'przystanął': 520, 'przyzwyczajenia': 521, 'psto': 522, 'pudło': 523, 'pędzie': 524, 'pęknie': 525, 'płaszczu': 526, 'raczej': 527, 'raz': 528, 'razie': 529, 'razu': 530, 'reakcja': 531, 'reszta': 532, 'robią': 533, 'rondel': 534, 'rozczulenia': 535, 'rozjaśniła': 536, 'rozkazująco': 537, 'rozpalił': 538, 'rozparty': 539, 'rozpoznał': 540, 'rozprawia': 541, 'roztargnionym': 542, 'rubińskiego': 543, 'ruda': 544, 'rytmicznie': 545, 'rzucała': 546, 'równało': 547, 'ręce': 550, 'rękawiczkę': 551, 'salonu': 552, 'sam': 554, 'samym': 555, 'sapać': 556, 'serca': 557, 'siebie': 560, 'siedział': 562, 'siostra': 563, 'siódmego': 564, 'się': 595, 'siły': 596, 'skarżył': 598, 'skrwawionym': 599, 'skuteczniej': 600, 'skórką': 601, 'skórzanej': 602, 'skórzaną': 603, 'sobie': 604, 'sobą': 606, 'spabażuru': 607, 'spadła': 608, 'spojrzał': 610, 'spojrzała': 611, 'spojrzeniem': 613, 'spokojnie': 614, 'spostrzegł': 615, 'sposób': 617, 'sposępniał': 618, 'spustoszenie': 619, 'stan': 620, 'stanu': 621, 'stały': 622, 'stole': 624, 'stracił': 625, 'strasznie': 626, 'stuknęło': 627, 'sufit': 628, 'sunęła': 629, 'swego': 631, 'swych': 632, 'szary': 633, 'szczególnej': 634, 'szew': 635, 'szorowała': 636, 'szybkością': 637, 'szybę': 638, 'słuchaj': 639, 'słyszał': 640, 'tak': 645, 'taki': 646, 'takie': 647, 'takim': 648, 'talerze': 649, 'tam': 650, 'tamten': 653, 'tego': 655, 'tej': 656, 'temu': 657, 'ten': 660, 'teraz': 661, 'to': 666, 'trzymał': 667, 'trzymała': 668, 'tumanie': 669, 'twarz': 671, 'tyle': 672, 'tylko': 674, 'tym': 677, 'tymczasem': 678, 'tę': 679, 'tępym': 680, 'tłumaczył': 681, 'u': 682, 'ulicy': 684, 'umył': 685, 'urządzić': 686, 'uspokoiło': 687, 'usta': 688, 'ustanku': 689, 'utkwiła': 690, 'uwagę': 691, 'ułożyło': 692, 'uśmiech': 693, 'uśmiechnął': 694, 'w': 723, 'wagi': 724, 'walił': 725, 'ważne': 726, 'wciąż': 727, 'wesołą': 728, 'wiatr': 730, 'wiatru': 731, 'widmar': 742, 'widmara': 745, 'widmarowi': 746, 'widział': 747, 'widziałam': 749, 'wieczoru': 751, 'wiedział': 753, 'wiedzieć': 754, 'wielkie': 755, 'wielkiego': 756, 'wieźli': 757, 'wizytę': 758, 'więc': 760, 'więcej': 761, 'wobec': 762, 'wrócił': 763, 'wróciłeś': 764, 'wszedł': 765, 'wszystko': 769, 'wyblakłe': 770, 'wyciągały': 771, 'wyciągnął': 772, 'wydawało': 774, 'wydało': 777, 'wydały': 778, 'wydyma': 779, 'wyglądał': 780, 'wyglądała': 781, 'wyjedziesz': 782, 'wykonywali': 783, 'wynikał': 784, 'wyrachowaniem': 785, 'wyrzucona': 786, 'wysiłkiem': 787, 'wyszedł': 788, 'wyuczony': 789, 'wył': 790, 'wzajemne': 791, 'wzbudzały': 792, 'wzrokiem': 793, 'wówczas': 795, 'wątpliwości': 796, 'węgła': 797, 'własnego': 798, 'właściwie': 799, 'właśnie': 800, 'włosy': 801, 'wściekłości': 802, 'wśród': 803, 'z': 818, 'za': 820, 'zabryzgując': 821, 'zachowanie': 822, 'zaczął': 823, 'zadowolenie': 824, 'zagadka': 825, 'zakurzona': 826, 'zakłopotaniem': 827, 'zamknął': 829, 'zanik': 830, 'zaproponowano': 831, 'zapukano': 832, 'zaraz': 833, 'zastygł': 834, 'zasypany': 835, 'zatracenie': 836, 'zatraceniem': 837, 'zatraciła': 838, 'zauważył': 840, 'zawiniętą': 841, 'zawrotnym': 842, 'zawsze': 843, 'zbagatelizować': 844, 'zbliżając': 845, 'zbliżającą': 846, 'ze': 848, 'zgubiona': 849, 'zgubą': 850, 'ziemię': 851, 'ziemniaki': 852, 'zimno': 853, 'zjawiający': 854, 'zjawił': 855, 'zjawiła': 856, 'zmieszana': 857, 'znaleźć': 858, 'znikający': 859, 'znowu': 860, 'znów': 861, 'zobaczył': 862, 'zostawiło': 863, 'zrobiło': 864, 'zrozumiał': 865, 'zupełnie': 867, 'zza': 868, 'złamaną': 869, 'łzy': 870, 'łóżka': 871, 'śledziami': 872, 'śliną': 873, 'śmierci': 874, 'śmietnisko': 875, 'środku': 876, 'światło': 877, 'świdrującym': 878, 'źle': 880, 'że': 894, 'żona': 895, 'żonę': 896, 'żółty': 899, 'żółtą': 900}\n",
      "tensor([141, 678, 771, 801, 818, 262, 428,  75, 271, 182,   4, 803, 371, 544,\n",
      "        427, 178,  31, 781, 227, 294, 786, 514, 255, 349, 875, 491, 831, 686,\n",
      "        259, 473,  13, 383, 243, 666, 726, 268,   8, 169, 538, 426, 455, 417,\n",
      "        852, 214, 685, 534,   4, 723, 677, 555,  88, 742, 304, 595, 650, 214,\n",
      "        818, 494, 508, 153, 631, 123, 840, 846, 595, 281, 390, 487, 530, 540,\n",
      "        896, 856, 595, 868, 797, 214, 629, 356, 388, 614, 214, 456,  46, 723,\n",
      "        103, 526, 214, 723, 412, 602,  85, 498, 668, 233, 441, 841, 723, 155,\n",
      "        763, 113, 123, 214, 723, 509, 359,  13, 383, 516, 372, 177, 760,  77,\n",
      "        512, 595, 113, 560, 431,  50, 495, 730, 181, 383,  49,  94, 424, 742,\n",
      "        480,  52, 101,  13,  71, 102,  66, 723, 842, 524, 309, 352, 300,  15,\n",
      "        236, 270, 383, 608, 349, 851,  56, 496, 391, 723, 123, 214, 829, 595,\n",
      "        349, 251, 290, 723, 483, 257, 113, 133, 832,  68, 349, 256, 493, 895,\n",
      "        227, 317, 595, 774, 394,  93, 880, 595,  92, 749, 227,  76, 764, 742,\n",
      "        788, 214, 124, 661, 615, 894, 243, 626, 857, 849, 214, 894, 867, 838,\n",
      "        449, 352, 606, 440, 688, 214, 562, 723, 354, 439,   4, 159, 723,  72,\n",
      "        357, 865, 769, 864, 317, 595, 492, 853, 214, 465, 894, 595, 477, 176,\n",
      "        601,  62, 303, 454, 349, 151, 290, 645, 542, 793, 894, 383, 840, 227,\n",
      "        779, 595, 731, 349, 624, 443, 595, 403, 145, 285, 275, 607, 546, 877,\n",
      "        674, 349, 472, 214,  96, 871, 628, 214, 532, 476,  46, 723,  78,  62,\n",
      "        464,  87, 282, 180, 411, 760,  57, 448, 595, 128, 116, 230,  43, 799,\n",
      "        505, 434, 746, 777, 595, 894,  62, 618, 290, 362, 671, 240, 536, 595,\n",
      "        214, 861, 855, 595, 349, 389, 789, 693, 442, 302, 645, 162, 214, 489,\n",
      "        214, 645, 545, 783, 769, 894, 774, 299, 595, 727, 894, 383, 533, 434,\n",
      "        290, 171, 349, 232, 599, 152, 349,  91, 550, 159, 367, 438, 635, 482,\n",
      "        349, 560, 818, 827, 227, 160, 295, 791, 824, 660, 142, 617, 497, 784,\n",
      "        527, 818, 521, 405, 818, 501, 802, 723, 136,  33, 745, 769, 595,  73,\n",
      "        692, 214, 687,  46, 666, 458, 531, 459, 358, 322, 277, 515, 214, 277,\n",
      "        863, 723, 401, 619, 214, 397, 113, 510, 595,  95, 159, 742, 598, 595,\n",
      "        723, 660, 617, 762, 264, 349, 830, 444,   8, 169, 485, 164, 818,  32,\n",
      "        279,  79, 349,  82, 468, 484, 383, 753, 554, 227,  26,  43, 500, 161,\n",
      "        519,  70, 620, 745, 172, 818, 146, 723, 248, 529, 159, 742, 818,  63,\n",
      "        765, 113, 552, 780, 645, 880,  43, 646,  25, 214, 899, 894, 414, 214,\n",
      "        150, 723, 476, 778, 595, 770, 301, 481, 281, 657, 867, 355, 469, 100,\n",
      "        822, 745, 518,  23, 353, 420, 823, 556, 645, 175, 214, 818, 648, 787,\n",
      "        894, 265, 170, 777, 595, 894, 742, 833, 525, 491,  24, 214, 821, 671,\n",
      "        264, 873, 681, 317, 537, 214, 386, 894, 319, 362, 858, 595, 723, 247,\n",
      "        860, 349, 457,  39,  84, 349, 624, 622,  36, 649, 848, 872, 349, 154,\n",
      "        730, 725, 723, 133, 869, 305, 383, 845, 595, 366, 113, 502, 214, 383,\n",
      "        470,  29, 640, 227, 446, 818, 503,  35, 272, 723, 499, 639, 169, 820,\n",
      "        118, 782, 366, 113,  14, 349, 429, 253, 870, 398, 383, 423,  65, 596,\n",
      "        506, 792, 723, 401,  74, 113, 231, 504,  49, 666, 392, 129, 114, 214,\n",
      "        306, 240,  55,  21, 595, 798, 535,  28, 753, 894, 173, 317, 385, 850,\n",
      "        837, 595, 723, 249, 216,   4, 647, 836, 547, 595, 370, 310, 370, 761,\n",
      "        674, 312, 874,  62, 653, 829, 820, 606, 133, 214, 463, 528, 438, 610,\n",
      "        514, 638, 349, 899, 134, 227, 723, 149, 274,  17, 245, 466,  65, 148,\n",
      "        139, 653, 474, 728, 318, 461, 138, 564, 757, 463, 260, 349, 284, 563,\n",
      "        636, 214, 320, 550, 349, 660, 554, 899, 274, 854, 595, 214, 859,  23,\n",
      "        689, 454, 848, 631, 471, 396, 268,   8, 169, 467, 241, 900, 603, 551,\n",
      "        749, 227, 254, 611, 317, 723, 422, 350, 878, 613, 383, 754,  90, 777,\n",
      "        299, 595, 237, 894, 244,  19,  38, 655, 751, 486, 363, 844, 769, 234,\n",
      "        126, 113, 123, 742,  54, 130, 598, 595, 349,  51, 557, 292,  98, 488,\n",
      "        368, 290, 655, 751,  47, 511, 894, 818, 785, 541, 672, 411, 632, 119,\n",
      "          9, 677, 600, 425, 311, 691, 454, 349, 404, 393, 680, 613, 517, 604,\n",
      "        100, 435, 543,  80, 113, 656,  83, 666, 413, 293, 755, 796, 321, 296,\n",
      "        436, 450, 235, 147, 634, 724, 215, 411, 679, 758, 406, 448, 140, 682,\n",
      "         69, 522, 460, 445, 411, 677,  19, 115,  28, 795, 690, 299, 723, 179,\n",
      "        227, 228, 825, 818, 418, 742, 366, 520, 349, 876,  67,  82, 818, 174,\n",
      "        627, 416, 388, 135,  37, 742, 862, 411, 451, 269, 307, 723, 143, 684,\n",
      "        127, 402, 595, 723, 419, 826, 747, 246, 229, 723, 669, 723, 125, 562,\n",
      "        539,  62, 653,  43,  53, 633, 835, 283,  13, 694, 595, 227, 843, 349,\n",
      "        258, 667, 137, 399, 523, 117, 432, 238, 480, 742, 214, 362, 625, 164,\n",
      "        818, 421, 250, 790,  86, 291, 308, 818, 637,   0, 252, 795, 666, 800,\n",
      "        349, 684,  20, 261, 478, 756, 323, 621,  97, 349, 278,  89, 742, 396,\n",
      "        268,   8, 169, 430,  16, 214,  31,  34, 144, 772, 415, 550, 508, 560,\n",
      "        610, 723, 384, 214, 834])\n"
     ]
    }
   ],
   "source": [
    "#mapping sentence to tensor\n",
    "with open('../../data/text_data/other/csv/text_10.txt', 'r', encoding='utf-8') as f:\n",
    "    sentence = f.read()\n",
    "\n",
    "dc = {s: i for i, s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "print(dc)\n",
    "\n",
    "r = [dc[i] for i in sentence.replace(',', '').split()]\n",
    "sentence_int = torch.tensor(r)\n",
    "print(sentence_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7717,  0.7052,  0.3514],\n",
      "        [-0.1407, -0.5498,  0.0912],\n",
      "        [-0.0992, -1.1203,  0.2032],\n",
      "        ...,\n",
      "        [-1.1655,  0.6826,  0.4542],\n",
      "        [ 0.0486, -0.2123, -1.5648],\n",
      "        [ 0.8153, -0.1479, -0.0280]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6052,  0.8232],\n",
       "        [-0.2322, -0.3478],\n",
       "        [-0.3933, -0.6524],\n",
       "        ...,\n",
       "        [-0.1898,  0.3616],\n",
       "        [-0.2617, -0.8783],\n",
       "        [ 0.2833,  0.0998]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "#embed data to attention-friendly tensor format\n",
    "vocab_size = 50000\n",
    "torch.manual_seed(2137)\n",
    "embed = nn.Embedding(vocab_size, 3)\n",
    "embedded_sentence = embed(sentence_int).detach()\n",
    "print(embedded_sentence)\n",
    "\n",
    "d = embedded_sentence.shape[1]  # Dimension of embeddings\n",
    "d_q, d_k, d_v = 2, 2, 4\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d, d_q))\n",
    "W_key = torch.nn.Parameter(torch.rand(d, d_k))\n",
    "W_value = torch.nn.Parameter(torch.rand(d, d_v))\n",
    "query = embedded_sentence @ W_query\n",
    "key = embedded_sentence @ W_key\n",
    "value = embedded_sentence @ W_value\n",
    "\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8215,  0.6823,  0.7749,  0.9758],\n",
      "        [-0.4479, -0.3549, -0.3947, -0.3686],\n",
      "        [-0.7337, -0.5857, -0.6543, -0.6472],\n",
      "        ...,\n",
      "        [-0.0591, -0.0384, -0.0346,  0.0412],\n",
      "        [-0.7366, -0.5887, -0.6592, -0.6590],\n",
      "        [ 0.2011,  0.1724,  0.1999,  0.2941]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "attention_scores = query @ key.T\n",
    "attention_scores = attention_scores / math.sqrt(d_k)\n",
    "attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "\n",
    "context_vector = attention_weights @ value\n",
    "print(context_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d, d_q, d_k, d_v):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.d = d\n",
    "        self.d_q = d_q\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        \n",
    "        self.W_query = nn.Parameter(torch.rand(d, d_q))\n",
    "        self.W_key = nn.Parameter(torch.rand(d, d_k))\n",
    "        self.W_value = nn.Parameter(torch.rand(d, d_v))\n",
    "\n",
    "    def forward(self, x):\n",
    "        Q = x @ self.W_query\n",
    "        K = x @ self.W_key\n",
    "        V = x @ self.W_value\n",
    "        attention_scores = Q @ K.T / math.sqrt(self.d_k)\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        context_vector = attention_weights @ V\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([901, 4])\n",
      "tensor([[ 0.4193,  0.8618,  1.3202,  1.0335],\n",
      "        [-0.2001, -0.3464, -0.6208, -0.4897],\n",
      "        [-0.3563, -0.6410, -1.1075, -0.8732],\n",
      "        ...,\n",
      "        [ 0.1225,  0.3949,  0.4470,  0.3118],\n",
      "        [-0.3341, -0.6487, -1.0563, -0.8221],\n",
      "        [ 0.0609,  0.0964,  0.1713,  0.1478]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sa = SelfAttention(d=3, d_q=2, d_k=2, d_v=4)\n",
    "cv = sa(embedded_sentence)\n",
    "print(cv.shape)\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniGPT(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, seq_len):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_emb = nn.Embedding(seq_len, embed_dim)\n",
    "        self.attn = nn.TransformerEncoderLayer(embed_dim, nhead=4)\n",
    "        self.transformer = nn.TransformerEncoder(self.attn, num_layers=2)\n",
    "        self.fc_out = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
    "        x = self.token_emb(x) + self.pos_emb(positions)\n",
    "        x = self.transformer(x)  # (seq, batch, embed)\n",
    "        return self.fc_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, prompt, max_len=50):\n",
    "    model.eval()\n",
    "    tokens = tokenizer(prompt)\n",
    "    input_ids = torch.tensor(tokens).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(input_ids.size(1)).to(\"cuda\")\n",
    "        logits = model(input_ids, tgt_mask=tgt_mask)\n",
    "        next_token = logits[:, -1, :].argmax(-1, keepdim=True)\n",
    "        input_ids = torch.cat((input_ids, next_token), dim=1)\n",
    "\n",
    "    return tokenizer.decode(input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_ff):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_ff, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        attn_output, _ = self.self_attn(x, x, x, attn_mask=src_mask)\n",
    "        x = self.norm1(x + attn_output)\n",
    "        ff_output = self.ff(x)\n",
    "        return self.norm2(x + ff_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_ff):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n",
    "        self.cross_attn = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_ff, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None):\n",
    "        # Masked self-attention\n",
    "        self_attn_output, _ = self.self_attn(tgt, tgt, tgt, attn_mask=tgt_mask)\n",
    "        x = self.norm1(tgt + self_attn_output)\n",
    "\n",
    "        # Cross-attention with encoder output (memory)\n",
    "        cross_attn_output, _ = self.cross_attn(x, memory, memory, attn_mask=memory_mask)\n",
    "        x = self.norm2(x + cross_attn_output)\n",
    "\n",
    "        # Feedforward\n",
    "        ff_output = self.ff(x)\n",
    "        return self.norm3(x + ff_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerCrossAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512, nhead=8, num_layers=6, dim_ff=2048, max_len=100):\n",
    "        super().__init__()\n",
    "        self.token_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "\n",
    "        # Stack encoder layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, nhead, dim_ff) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Stack decoder layers\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, nhead, dim_ff) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        # Positional embeddings\n",
    "        src_pos = torch.arange(0, src.size(1), device=src.device).unsqueeze(0)\n",
    "        tgt_pos = torch.arange(0, tgt.size(1), device=tgt.device).unsqueeze(0)\n",
    "\n",
    "        src = self.token_embed(src) + self.pos_embed(src_pos)\n",
    "        tgt = self.token_embed(tgt) + self.pos_embed(tgt_pos)\n",
    "\n",
    "        # Encode\n",
    "        for layer in self.encoder_layers:\n",
    "            src = layer(src, src_mask)\n",
    "\n",
    "        memory = src  # encoder output\n",
    "\n",
    "        # Decode\n",
    "        for layer in self.decoder_layers:\n",
    "            tgt = layer(tgt, memory, tgt_mask, src_mask)\n",
    "\n",
    "        return self.fc_out(tgt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Generation without atteniton</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import unidecode\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>N-gram method</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['łzy', 'padały'], 'na'), (['padały', 'na'], 'cremoński'), (['na', 'cremoński'], 'lakier')]\n"
     ]
    }
   ],
   "source": [
    "with open ('../../data/text_data/other/csv/text_1.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "len(text.split())\n",
    "\n",
    "test_sentence = text.split()\n",
    "\n",
    "trigrams = [([test_sentence[i], test_sentence[i + 1]], test_sentence[i + 2])\n",
    "            for i in range(len(test_sentence) - 2)]\n",
    "chunk_len=len(trigrams)\n",
    "print(trigrams[:3])\n",
    "\n",
    "vocab = set(test_sentence)\n",
    "voc_len=len(vocab)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "word_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp=[]\n",
    "tar=[]\n",
    "for context, target in trigrams:\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        inp.append(context_idxs)\n",
    "        targ = torch.tensor([word_to_ix[target]], dtype=torch.long)\n",
    "        tar.append(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size*2, hidden_size, n_layers,batch_first=True,\n",
    "                          bidirectional=False)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "        self.attention = nn.MultiheadAttention()\n",
    "        self.normalization = nn.LayerNorm()\n",
    "        self.flatten = nn.Flatten()\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        input = self.encoder(input.view(1, -1))\n",
    "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
    "        output = self.decoder(output.view(1, -1))\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inp, target):\n",
    "    hidden = decoder.init_hidden()\n",
    "    decoder.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    for c in range(chunk_len):\n",
    "        output, hidden = decoder(inp[c], hidden)\n",
    "        loss += criterion(output, target[c])\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data.item() / chunk_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, math\n",
    "\n",
    "def time_since(since):\n",
    "    s = time.time() - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2m 7s (100 16%) 0.0001]\n",
      "[4m 8s (200 33%) 0.0001]\n",
      "[6m 22s (300 50%) 0.0000]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 300\n",
    "print_every = 100\n",
    "plot_every = 10\n",
    "hidden_size = 100\n",
    "n_layers = 1\n",
    "lr = 0.015\n",
    "train_on_gpu = False\n",
    "\n",
    "decoder = RNN(voc_len, hidden_size, voc_len, n_layers)\n",
    "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "start = time.time()\n",
    "all_losses = []\n",
    "loss_avg = 0\n",
    "if(train_on_gpu):\n",
    "    decoder.cuda()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    loss = train(inp,tar)       \n",
    "    loss_avg += loss\n",
    "\n",
    "    if epoch % print_every == 0:\n",
    "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 50, loss))\n",
    "#         print(evaluate('ge', 200), '\\n')\n",
    "\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(loss_avg / plot_every)\n",
    "        loss_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(prime_str:str, predict_len:int=100, temperature:float=0.8) -> str:\n",
    "    decoder.eval()\n",
    "    hidden = decoder.init_hidden()\n",
    "\n",
    "    for p in range(predict_len):\n",
    "        \n",
    "        prime_input = torch.tensor([word_to_ix[w] for w in prime_str.split()], dtype=torch.long)\n",
    "        inp = prime_input[-2:] #last two words as input\n",
    "        output, hidden = decoder(inp, hidden)\n",
    "        \n",
    "        # Sample from the network as a multinomial distribution\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Add predicted word to string and use as next input\n",
    "        predicted_word = list(word_to_ix.keys())[list(word_to_ix.values()).index(top_i)]\n",
    "        prime_str += \" \" + predicted_word\n",
    "#         inp = torch.tensor(word_to_ix[predicted_word], dtype=torch.long)\n",
    "\n",
    "    return prime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nie lakier się nie wolno było niszczyć przedmiotu na który ojciec biedaczysko wydał całą schedę po luizie otarła je lewą umęczoną ręką wszedł adam zawiało wodą kwiatową maréchal niel starannie domykał drzwi za sobą trwała dalej w bezruchu pan dyrektor był nieobecny a róża stała ppiecem czekając kiedy panna aniela bądska ukończy gamy i zechce łaskawie zaakompaniować jedynej uczennicy papy moment musical szuberta jedynej uczennicy pierwszej adeptce skrzypiec warszawskiego konserwatorium na tamce czarnej chudej dziewczynie z rumieńcami latającymi jak płomień po śniadych policzkach z lśniącym długim warkoczem z kacapską wymową i z niemodnym medalionem na szyi to wszystko było nowe nowe także'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing...wroks\n",
    "evaluate('nie lakier', temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': decoder.state_dict(),\n",
    "    'optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    # you may add other information to add \n",
    "}\n",
    "torch.save(checkpoint, 'checkpoint.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `RNN([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `RNN([...]` with `torch.export.export(..., strict=False)`... ❌\n",
      "[torch.onnx] Obtain model graph for `RNN([...]` with `torch.export.export`...\n",
      "[torch.onnx] Obtain model graph for `RNN([...]` with `torch.export.export`... ❌\n",
      "[torch.onnx] Obtain model graph for `RNN([...]` with Torch Script...\n",
      "[torch.onnx] Obtain model graph for `RNN([...]` with Torch Script... ❌\n",
      "[torch.onnx] Obtain model graph for `RNN([...]` with internal Dynamo apis...\n",
      "[torch.onnx] Obtain model graph for `RNN([...]` with internal Dynamo apis... ❌\n"
     ]
    },
    {
     "ename": "TorchExportError",
     "evalue": "Failed to export the model with torch.export. \u001b[96mThis is step 1/3\u001b[0m of exporting the model to ONNX. Next steps:\n- Modify the model code for `torch.export.export` to succeed. Refer to https://pytorch.org/docs/stable/generated/exportdb/index.html for more information.\n- Debug `torch.export.export` and summit a PR to PyTorch.\n- Create an issue in the PyTorch GitHub repository against the \u001b[96m*torch.export*\u001b[0m component and attach the full error stack as well as reproduction scripts.\n\n## Exception summary\n\n<class 'TypeError'>: missing a required argument: 'hidden'\n\n(Refer to the full stack trace above for more information.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_capture_strategies.py:110\u001b[0m, in \u001b[0;36mCaptureStrategy.__call__\u001b[1;34m(self, model, args, kwargs, dynamic_shapes)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     exported_program \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_capture_strategies.py:186\u001b[0m, in \u001b[0;36mTorchExportNonStrictStrategy._capture\u001b[1;34m(self, model, args, kwargs, dynamic_shapes)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mexc\u001b[38;5;241m.\u001b[39mUserError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;66;03m# Refine the dynamic shapes based on the suggested fixes.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\__init__.py:368\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature)\u001b[0m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExporting a ScriptModule is not supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaybe try converting your ScriptModule to an ExportedProgram \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing `TS2EPConverter(mod, args, kwargs).convert()` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    367\u001b[0m     )\n\u001b[1;32m--> 368\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_module_call_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_module_call_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\_trace.py:1035\u001b[0m, in \u001b[0;36m_log_export_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         log_export_usage(\n\u001b[0;32m   1030\u001b[0m             event\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport.error.unclassified\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1031\u001b[0m             \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39merror_type,\n\u001b[0;32m   1032\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m   1033\u001b[0m             flags\u001b[38;5;241m=\u001b[39m_EXPORT_FLAGS,\n\u001b[0;32m   1034\u001b[0m         )\n\u001b[1;32m-> 1035\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\_trace.py:1008\u001b[0m, in \u001b[0;36m_log_export_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1007\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m-> 1008\u001b[0m ep \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\exported_program.py:128\u001b[0m, in \u001b[0;36m_disable_prexisiting_fake_mode.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m unset_fake_temporarily():\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\_trace.py:1970\u001b[0m, in \u001b[0;36m_export\u001b[1;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature, pre_dispatch, allow_complex_guards_as_runtime_asserts, _is_torch_jit_trace)\u001b[0m\n\u001b[0;32m   1969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;129;01mand\u001b[39;00m export_training_ir_rollout_check():\n\u001b[1;32m-> 1970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_export_for_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreserve_module_call_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_module_call_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1977\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1979\u001b[0m (\n\u001b[0;32m   1980\u001b[0m     args,\n\u001b[0;32m   1981\u001b[0m     kwargs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1984\u001b[0m     dynamic_shapes,\n\u001b[0;32m   1985\u001b[0m ) \u001b[38;5;241m=\u001b[39m _process_export_inputs(mod, args, kwargs, dynamic_shapes)\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\_trace.py:1035\u001b[0m, in \u001b[0;36m_log_export_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1029\u001b[0m         log_export_usage(\n\u001b[0;32m   1030\u001b[0m             event\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport.error.unclassified\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1031\u001b[0m             \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39merror_type,\n\u001b[0;32m   1032\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m   1033\u001b[0m             flags\u001b[38;5;241m=\u001b[39m_EXPORT_FLAGS,\n\u001b[0;32m   1034\u001b[0m         )\n\u001b[1;32m-> 1035\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\_trace.py:1008\u001b[0m, in \u001b[0;36m_log_export_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1007\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m-> 1008\u001b[0m ep \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\exported_program.py:128\u001b[0m, in \u001b[0;36m_disable_prexisiting_fake_mode.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m unset_fake_temporarily():\n\u001b[1;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\_trace.py:1834\u001b[0m, in \u001b[0;36m_export_for_training\u001b[1;34m(mod, args, kwargs, dynamic_shapes, strict, preserve_module_call_signature)\u001b[0m\n\u001b[0;32m   1823\u001b[0m export_func \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1824\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\n\u001b[0;32m   1825\u001b[0m         _strict_export_lower_to_aten_ir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1832\u001b[0m     )\n\u001b[0;32m   1833\u001b[0m )\n\u001b[1;32m-> 1834\u001b[0m export_artifact \u001b[38;5;241m=\u001b[39m \u001b[43mexport_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[operator]\u001b[39;49;00m\n\u001b[0;32m   1835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1836\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreserve_module_call_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreserve_module_call_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1841\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moriginal_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1842\u001b[0m \u001b[43m    \u001b[49m\u001b[43morig_in_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morig_in_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1843\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_complex_guards_as_runtime_asserts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_torch_jit_trace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1847\u001b[0m export_graph_signature \u001b[38;5;241m=\u001b[39m export_artifact\u001b[38;5;241m.\u001b[39maten\u001b[38;5;241m.\u001b[39msig\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\_trace.py:1734\u001b[0m, in \u001b[0;36m_non_strict_export\u001b[1;34m(mod, args, kwargs, dynamic_shapes, preserve_module_call_signature, pre_dispatch, original_state_dict, orig_in_spec, allow_complex_guards_as_runtime_asserts, _is_torch_jit_trace, dispatch_tracing_mode)\u001b[0m\n\u001b[0;32m   1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _aot_export_non_strict\n\u001b[0;32m   1727\u001b[0m (\n\u001b[0;32m   1728\u001b[0m     fake_mode,\n\u001b[0;32m   1729\u001b[0m     fake_args,\n\u001b[0;32m   1730\u001b[0m     fake_kwargs,\n\u001b[0;32m   1731\u001b[0m     equalities_inputs,\n\u001b[0;32m   1732\u001b[0m     original_signature,\n\u001b[0;32m   1733\u001b[0m     dynamic_shapes,\n\u001b[1;32m-> 1734\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fake_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_is_torch_jit_trace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_is_torch_jit_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_complex_guards_as_runtime_asserts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_complex_guards_as_runtime_asserts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# for shape env initialization\u001b[39;49;00m\n\u001b[0;32m   1741\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m fake_params_buffers \u001b[38;5;241m=\u001b[39m _fakify_params_buffers(fake_mode, mod)\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_export\\non_strict_utils.py:153\u001b[0m, in \u001b[0;36mmake_fake_inputs\u001b[1;34m(nn_module, args, kwargs, dynamic_shapes, _is_torch_jit_trace, allow_complex_guards_as_runtime_asserts)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# TODO(avik): refactor Dynamo to avoid duplication of the following code\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# between non-strict and strict.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;66;03m# Specifically, here (non-strict) we do the following pre-tracing steps:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m#   - output_graph.py fakifies inputs.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m#   - [post-tracing] guards.py processes input shape equalities.\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m combined_args \u001b[38;5;241m=\u001b[39m \u001b[43m_combine_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m _check_dynamic_shapes(combined_args, dynamic_shapes)\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\export\\dynamic_shapes.py:592\u001b[0m, in \u001b[0;36m_combine_args\u001b[1;34m(f, args, kwargs, _is_torch_jit_trace)\u001b[0m\n\u001b[0;32m    591\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39marguments\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:3195\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3191\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3192\u001b[0m \u001b[38;5;124;03mand `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3193\u001b[0m \u001b[38;5;124;03mif the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3194\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:3110\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3109\u001b[0m                 msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mformat(arg\u001b[38;5;241m=\u001b[39mparam\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m-> 3110\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3112\u001b[0m     \u001b[38;5;66;03m# We have a positional argument to process\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: missing a required argument: 'hidden'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTorchExportError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m example_inputs \u001b[38;5;241m=\u001b[39m ((\u001b[38;5;241m32\u001b[39m),)\n\u001b[1;32m----> 2\u001b[0m onnx_program \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m onnx_program\u001b[38;5;241m.\u001b[39moptimize()\n\u001b[0;32m      4\u001b[0m onnx_program\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_classifier_model.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\__init__.py:351\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, dynamic_axes, keep_initializers_as_inputs, dynamo, external_data, dynamic_shapes, custom_translation_table, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining, **_)\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    350\u001b[0m         args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m--> 351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_compat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_translation_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_translation_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexternal_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexternal_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:304\u001b[0m, in \u001b[0;36mexport_compat\u001b[1;34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, custom_translation_table, dynamic_axes, dynamic_shapes, keep_initializers_as_inputs, external_data, report, optimize, verify, profile, dump_exported_program, artifacts_dir, fallback, **_)\u001b[0m\n\u001b[0;32m    302\u001b[0m             registry\u001b[38;5;241m.\u001b[39mregister_op(torch_op, op, is_complex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     onnx_program \u001b[38;5;241m=\u001b[39m \u001b[43m_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregistry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdump_exported_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdump_exported_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43martifacts_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifacts_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fallback:\n",
      "File \u001b[1;32mc:\\Users\\X\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\_internal\\exporter\\_core.py:1292\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(model, args, kwargs, registry, dynamic_shapes, input_names, output_names, report, verify, profile, dump_exported_program, artifacts_dir, verbose)\u001b[0m\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m first_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m         \u001b[38;5;66;03m# NOTE: We only throw the torch.export (first) exception because we want to\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m         \u001b[38;5;66;03m# focus on the torch.export.export error. Errors from other strategies like\u001b[39;00m\n\u001b[0;32m   1290\u001b[0m         \u001b[38;5;66;03m# torch.jit.trace is due to the fallback and can be confusing to users.\u001b[39;00m\n\u001b[0;32m   1291\u001b[0m         \u001b[38;5;66;03m# We save all errors in the error report.\u001b[39;00m\n\u001b[1;32m-> 1292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m _errors\u001b[38;5;241m.\u001b[39mTorchExportError(\n\u001b[0;32m   1293\u001b[0m             _STEP_ONE_ERROR_MESSAGE\n\u001b[0;32m   1294\u001b[0m             \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m   1295\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mError report has been saved to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreport_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1296\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m report\n\u001b[0;32m   1297\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1298\u001b[0m             )\n\u001b[0;32m   1299\u001b[0m             \u001b[38;5;241m+\u001b[39m _summarize_exception_stack(first_error)\n\u001b[0;32m   1300\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfirst_error\u001b[39;00m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m program \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dump_exported_program:\n",
      "\u001b[1;31mTorchExportError\u001b[0m: Failed to export the model with torch.export. \u001b[96mThis is step 1/3\u001b[0m of exporting the model to ONNX. Next steps:\n- Modify the model code for `torch.export.export` to succeed. Refer to https://pytorch.org/docs/stable/generated/exportdb/index.html for more information.\n- Debug `torch.export.export` and summit a PR to PyTorch.\n- Create an issue in the PyTorch GitHub repository against the \u001b[96m*torch.export*\u001b[0m component and attach the full error stack as well as reproduction scripts.\n\n## Exception summary\n\n<class 'TypeError'>: missing a required argument: 'hidden'\n\n(Refer to the full stack trace above for more information.)"
     ]
    }
   ],
   "source": [
    "example_inputs = ((32),)\n",
    "onnx_program = torch.onnx.export(decoder, example_inputs, dynamo=True)\n",
    "onnx_program.optimize()\n",
    "onnx_program.save(\"image_classifier_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "\n",
    "q = Queue(maxsize=12)\n",
    "\n",
    "q.put(12)\n",
    "q.put(11)\n",
    "#get the oldest\n",
    "print(q.get())\n",
    "print(q.get())\n",
    "print(q._qsize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from enum import Enum\n",
    "from queue import Queue\n",
    "\n",
    "class Roles(Enum):\n",
    "    USER = 0\n",
    "    MODEL = 1\n",
    "\n",
    "MAX_TOKENS = 4096 * 2\n",
    "\n",
    "class ContextWindow:\n",
    "    def __init__(self, max_size:int=128, max_tokens:int=4096):\n",
    "        self.max_tokens = max_tokens\n",
    "        self.__history = []\n",
    "        self.max_tokens = max_tokens\n",
    "        \n",
    "        self.system_prompt = {\"role\": Roles.MODEL, \"content\": ''}\n",
    "        self.user_prompt = {\"role\": Roles.USER, \"content\": ''}\n",
    "    \n",
    "    #legacy\n",
    "    def _add_message_context(self, message:str, text:str):\n",
    "        message['context'] = text.split()\n",
    "        self.__history.append((message, message.split()))\n",
    "\n",
    "    def add_system_message(self, text:str) -> None:\n",
    "        self.system_prompt['context'] = text.split()\n",
    "        self.__history.append(self.system_prompt)\n",
    "\n",
    "    def add_user_message(self, text:str) -> None:\n",
    "        self.user_prompt['context'] = text.split()\n",
    "        self.__history.append(self.user_prompt)\n",
    "\n",
    "    def count_tokens(self) -> int:\n",
    "        counter:int = 0\n",
    "        for x in self.__history:\n",
    "            counter += len(x['context'])\n",
    "        return counter\n",
    "    \n",
    "    def count_conversation_length(self):\n",
    "        return len(self.__history)\n",
    "    \n",
    "    def get_history(self) -> None:\n",
    "        return self.__history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': <Roles.MODEL: 1>, 'content': '', 'context': ['hello', 'here']}, {'role': <Roles.MODEL: 1>, 'content': '', 'context': ['hello', 'here']}]\n"
     ]
    }
   ],
   "source": [
    "context = ContextWindow(max_size=128, max_tokens=MAX_TOKENS)\n",
    "\n",
    "context.add_system_message('hello there')\n",
    "context.add_system_message('hello here')\n",
    "context.count_tokens()\n",
    "context.count_conversation_length()\n",
    "print(context.get_history())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
